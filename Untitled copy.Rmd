/---
title: "CDC2023"
output: html_document
date: "2023-09-30"
---

### CDC 2023 - Health Science Track

```{r}
library(e1071)
library(dplyr)
library(ggplot2)
library(MASS)
library(rpart)
library(rpart.plot)
```

```{r}
data = read.csv("book1.csv")
data1 <- data[,-(1:2)]
data1[data1 == "?"] <- NA
data1[data1 == "None"] <- NA
```

```{r}
data2 <- data1 %>%
  dplyr::select(readmitted, everything()) %>%
  dplyr::select(-c(examide, citoglipton)) # remove factors with only 1 level.

data2[sapply(data2, is.character)] <- lapply(data2[sapply(data2, is.character)], as.factor)
# turn character variables into factors.
```

### GLM

Adjust the dependent variable "readmitted" to binary, with 0 = not readmitted, 1 = readmitted.

```{r}
data2_YorN <- data2 %>%
  mutate(readmitted = dplyr::recode(readmitted, "NO" = 0, '>30' = 1, '<30' = 1),
         age = dplyr::recode(age, "[0-10)" = 0, "[10-20)" = 1, "[20-30)" = 2, "[30-40)" = 3,
                      "[40-50)" = 4, "[50-60)" = 5, "[60-70)" = 6, "[70-80)" = 7,
                      "[80-90)" = 8, "[90-100)" = 9),
         readmitted = dplyr::recode(readmitted, "NO" = 0, ">30" = 1, "<30" = 2),
         weight = dplyr::recode(weight, "[0-25)" = 0, "[25-50)" = 1, "[50-75)" = 2, "[75-100)" = 3, 
                         "[100-125)" = 4, "[125-150)" = 5, "[150-175)" = 6, "[175-200)" = 7,
                         ">200" = 8),
         max_glu_serum = dplyr::recode(max_glu_serum, "Norm" = 0, ">200" = 1, ">300" = 2),
         diabetesMed = dplyr::recode(diabetesMed, "Yes" = 1, "No" = 0),
         change = dplyr::recode(change, "Yes" = 1, "No" = 0)
         ) %>%
  mutate_at(vars(metformin:metformin.pioglitazone), list(~recode(.,`No` = 0, "Down" = 1, "Steady" = 2,
                                                                 "Up" = 3)))
```

Split up the sample, randomly assigns a boolean to a new column "sample"
Use 80% of dataset as training set and 20% as test set

```{R}
sample <- sample(c(TRUE, FALSE), nrow(data2_YorN), replace=TRUE, prob=c(0.8,0.2))
train <- data2_YorN[sample, ]
test <- data2_YorN[!sample, ]
```

Generate glm moddel:

(By checking the correlation table between important variables(except for the variables of medicines from "metformin" to "metformin.pioglitazone") in Python when doing EDA, we find a correlation of 0.47 between time_in_hospital and num_medicines, which is considerable. So we delete the variable "num_medicines".)

```{r}
m <- glm(readmitted ~ race  + time_in_hospital + num_lab_procedures + num_procedures +
           number_diagnoses + admission_type_id 
          + number_inpatient + number_emergency + number_outpatient
         + metformin + repaglinide + nateglinide + chlorpropamide + glimepiride + 
           acetohexamide + glipizide + glyburide + tolbutamide + pioglitazone + 
           rosiglitazone + acarbose + miglitol + troglitazone + tolazamide + 
           insulin + glyburide.metformin + glipizide.metformin + glimepiride.pioglitazone 
         + metformin.rosiglitazone + metformin.pioglitazone,
         ,data = train, family = "binomial")
summary(m)
```

Apply stepwise method to reduce number of variables:

```{r}
mod_AIC <- step(m, trace=FALSE)
summary(mod_AIC)
nobs(mod_AIC)
```

Test Accuracy:

```{r}
test$pred <- mod_AIC %>% 
  predict(test, type = "response", na.rm = T)
```

```{r}
test$classify = ifelse(test$pred>0.5,1,0)
test = test[!is.na(test$classify),]
1 - sum(test$classify != test$readmitted) / nrow(test)
```

Accuracy = 0.62.


Again readjust the dependent variable "readmitted" to binary, with 0 = readmitted after 30 days, 1 = readmitted in 30 days.

```{r}
data2_LessorMore <- data2 %>%
  mutate(readmitted = dplyr::recode(readmitted, '<30' = 1, ">30" = 0),
         age = dplyr::recode(age, "[0-10)" = 0, "[10-20)" = 1, "[20-30)" = 2, "[30-40)" = 3,
                      "[40-50)" = 4, "[50-60)" = 5, "[60-70)" = 6, "[70-80)" = 7,
                      "[80-90)" = 8, "[90-100)" = 9),
         readmitted = dplyr::recode(readmitted, "NO" = 0, ">30" = 1, "<30" = 2),
         weight = dplyr::recode(weight, "[0-25)" = 0, "[25-50)" = 1, "[50-75)" = 2, "[75-100)" = 3, 
                         "[100-125)" = 4, "[125-150)" = 5, "[150-175)" = 6, "[175-200)" = 7,
                         ">200" = 8),
         max_glu_serum = dplyr::recode(max_glu_serum, "Norm" = 0, ">200" = 1, ">300" = 2),
         diabetesMed = dplyr::recode(diabetesMed, "Yes" = 1, "No" = 0),
         change = dplyr::recode(change, "Yes" = 1, "No" = 0)
         ) %>%
  mutate_at(vars(metformin:metformin.pioglitazone), list(~recode(.,`No` = 0, "Down" = 1, "Steady" = 2,
                                                                 "Up" = 3)))
```

Split up the sample, randomly assigns a boolean to a new column "sample"
Use 80% of dataset as training set and 20% as test set

```{R}
sample <- sample(c(TRUE, FALSE), nrow(data2_YorN), replace=TRUE, prob=c(0.8,0.2))
train2 <- data2_LessorMore[sample, ]
test2 <- data2_LessorMore[!sample, ]
```

Generate glm moddel:

(By checking the correlation table between important variables(except for the variables of medicines from "metformin" to "metformin.pioglitazone") in Python when doing EDA, we find a correlation of 0.47 between time_in_hospital and num_medicines, which is considerable. So we delete the variable "num_medicines".)

```{r}
m <- glm(readmitted ~ race  + time_in_hospital + num_lab_procedures + num_procedures +
           number_diagnoses + admission_type_id 
          + number_inpatient + number_emergency + number_outpatient
         + metformin + repaglinide + nateglinide + chlorpropamide + glimepiride + 
           acetohexamide + glipizide + glyburide + tolbutamide + pioglitazone + 
           rosiglitazone + acarbose + miglitol + troglitazone + tolazamide + 
           insulin + glyburide.metformin + glipizide.metformin + glimepiride.pioglitazone 
         + metformin.rosiglitazone + metformin.pioglitazone,
         ,data = train2, family = "binomial")
summary(m)
```
Compared to the last model, the independent variables show less significance for this one.
time_in_hospital, number_inpatient and number_outpatient are significant at a pretty high level in deciding whether the patient will be readmitted in one month or not. 
Most medicines still show negative coefficient, indicating that people taking this medicines are more likely to come back to hospital in a short period of time.

\newpage

### Decision Tree

Adjust data: remove numerical variables with more than 32 values.

```{r}
set.seed(150)
library(tree, quietly = TRUE)
data3 <- data2[sample(1:nrow(data2), 1000,
   replace=FALSE),] %>%
  dplyr::select(-c(diag_1, diag_2, diag_3, weight, payer_code,max_glu_serum,
                   num_medications, num_lab_procedures, medical_specialty, number_diagnoses,
                   A1Cresult, age, race))  %>%
  na.omit()

#use 80% of dataset as training set and 20% as test set
sample <- sample(c(TRUE, FALSE), nrow(data3), replace=TRUE, prob=c(0.8,0.2))
train1  <- data3[sample, ]
test1  <- data3[!sample, ]
```

The tree we got has only three nodes.

```{r}
CART.tree = tree(readmitted ~ ., data = train1)

summary(CART.tree)
```

```{r}
CART.tree = rpart(readmitted ~., data = train1)
```

```{r}
control = rpart.control(minsplit = 2, cp = 0)
rpart.plot(CART.tree, box.palette = "Blues")
```
Prediction and Accuracy:

```{r}
CART.Prediction <- predict(CART.tree, newdata = test1, type = "class")
results <- table(Prediction = CART.Prediction, Actual = test1$readmitted)
```

```{R}
Accuracy_1 <- sum(diag(results)) / sum(results)
Accuracy_1
```

```{R}
plotcp(CART.tree)
```
X-val relative error is lowest at 3, which means there is no need to prune the tree.




